{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-6-b44b59d0ff8e>, line 92)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-b44b59d0ff8e>\"\u001b[0;36m, line \u001b[0;32m92\u001b[0m\n\u001b[0;31m    if __name__ == '__main__':\u001b[0m\n\u001b[0m                             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import spacy\n",
    "import numpy as np\n",
    "import docx2txt\n",
    "import collections\n",
    "\n",
    "homeDir = '/home/ubuntu/writerAuthentification/dataset-1/'\n",
    "\n",
    "def listToString(s):  \n",
    "#Literally just copy-pasted this from geeks2geeks lol\n",
    "    str1 = \"\"  \n",
    "  \n",
    "    for ele in s:  \n",
    "        str1 += ele   \n",
    "     \n",
    "    return str1  \n",
    "\n",
    "\n",
    "def convertToPOS(text):\n",
    "#Converts text to POS using spacy. This particular method ignores punctuation and spaces\n",
    "\n",
    "\tposText = \"\"\n",
    "\tnlp = spacy.load(\"en_core_web_sm\")\n",
    "\tdoc = nlp(str(text))\n",
    "\n",
    "\tfor token in doc:\n",
    "\n",
    "\t\tif not(token.pos_ == 'SPACE' or token.pos_ == 'PUNCT'):\n",
    "\n",
    "\t\t\tposText = posText + \" \" + token.pos_ \n",
    "\t\t\n",
    "\treturn posText\n",
    "\n",
    "def identifyMostCommonGrams(text, N, X):\n",
    "\tmostFrequentGrams = np.empty(X)\n",
    "\n",
    "\tamountOfNGrams = len(text.split()) - (N-1)\n",
    "\tgramArray = ['','']\n",
    "\tindividualWordsList = text.split()\n",
    "\tgramWordsList = []\n",
    "\tfor i in range(amountOfNGrams):\n",
    "\t\tgramWordsList.append(0)\n",
    "\tgramFrequencyList = []\n",
    "\tfor i in range(amountOfNGrams):\n",
    "\t\tgramFrequencyList.append(0)\n",
    "\n",
    "\t#print(individualWordsList)\n",
    "\n",
    "\tfor q in range(len(individualWordsList)-(N-1)):\n",
    "\n",
    "\t\ttemp = \"\"\n",
    "\n",
    "\t\tfor i in range(N):\n",
    "\n",
    "\t\t\ttemp = temp + individualWordsList[i + q] + \" \"\n",
    "\n",
    "\t\tgramWordsList[q] = temp\n",
    "\n",
    "\t#print(gramWordsList)\n",
    "\n",
    "\tcounter = collections.Counter(gramWordsList)\n",
    "\treturn(counter.most_common(X))\n",
    "\n",
    "def main():\n",
    "\t\n",
    "\tfor dirNo, dirName in enumerate(sorted(os.listdir(homeDir)), start = 1):\n",
    "\t\tAuthorNGrams = []\n",
    "\t\t#traverse directory\n",
    "\t\t#print(\"Directory \" + dirName + \", number \" + str(dirNo) + \" recognized\")\n",
    "\t\t#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\t\tfor fileNo, fileName in enumerate(sorted(os.listdir(homeDir + dirName)), start = 1):\n",
    "\t\t\t#traverse file in directory\n",
    "\t\t\t#print(\"\t\tFile \" + fileName + \" from directory \" + dirName + \" recognized\")\n",
    "\t\t\t#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "\t\t\tif fileName.endswith('txt'):\n",
    "\n",
    "\t\t\t\twith open(homeDir + dirName + \"/\" + fileName, 'r', encoding = 'utf-8', errors = 'ignore') as f:\n",
    "\t\t\t\t\t\n",
    "\t\t\t\t\tAuthorNGrams += identifyMostCommonGrams(f.read(), 3, 5)\n",
    "                    \n",
    "\t\t\telif fileName.endswith('docx'):\n",
    "                \n",
    "\t\t\t\tcurrentFile = docx2txt.process(homeDir + dirName + \"/\" + fileName)\n",
    "\t\t\t\t\n",
    "\t\t\t\tAuthorNGrams += identifyMostCommonGrams(currentFile, 3, 5)\n",
    "\t\t\telse:\n",
    "\t\t\t\t\n",
    "\t\t\t\tprint(\"INVALID DOCTYPE!\")\n",
    "\t\tprint(\"The 5 most common N grams from author \" + str(dirNo) + \" are \" + str(collections.Counter(AuthorNGrams).most_common(5))\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "\tprint(\"initialized\")\n",
    "\n",
    "\tmain()\n",
    "\n",
    "print(\"completed\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "// apply setting to all current CodeMirror instances\n",
       "IPython.notebook.get_cells().map(\n",
       "    function(c) {  return c.code_mirror.options.indentWithTabs=true;  }\n",
       ");\n",
       "\n",
       "// make sure new CodeMirror instances created in the future also use this setting\n",
       "CodeMirror.defaults.indentWithTabs=true;\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "    %%javascript\n",
    "\n",
    "    // apply setting to all current CodeMirror instances\n",
    "    IPython.notebook.get_cells().map(\n",
    "        function(c) {  return c.code_mirror.options.indentWithTabs=true;  }\n",
    "    );\n",
    "\n",
    "    // make sure new CodeMirror instances created in the future also use this setting\n",
    "    CodeMirror.defaults.indentWithTabs=true;\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
